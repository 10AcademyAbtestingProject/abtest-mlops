{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Pandas an Numpy Libraries to use on manipulating our Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# To evaluate end result we have \n",
    "from sklearn.metrics import (accuracy_score, \n",
    "                            confusion_matrix,\n",
    "                            mean_squared_error, \n",
    "                            r2_score, \n",
    "                            mean_absolute_error)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import dvc.api\n",
    "import io\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from Scripts.exploration import Analysis\n",
    "from Scripts.cleaning import CleanDataFrame\n",
    "from Scripts.visualization import Plotters\n",
    "\n",
    "analyzer = Analysis()\n",
    "cleaner = CleanDataFrame()\n",
    "plotter = Plotters(w=7, h=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps to get the data\n",
    "\n",
    "1. Make sure you are in sync with the latest main branch.\n",
    "2. run `dvc pull` to get the latest data versions\n",
    "3. In the next cell change the `version` and `path` to access the file you want.\n",
    "\n",
    "you can find the file names by exploring the data folder.\n",
    "For the versions, follow this:\n",
    "\n",
    " - all files starting with `browser_` can be accessed starting from version=v1.1.1\n",
    " - all files starting with `brand_` can be accessed starting from version=v1.1.2\n",
    " - you can find the cleaned data with `device_make` converted to `brands` at version=v1.1\n",
    " - you can find the cleaned raw data at version=v1\n",
    " - you can find the raw data at version=v0\n",
    "  \n",
    "\n",
    "The last 3 files have the same name `AdSmartABdata.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 795 entries, 0 to 794\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   experiment   795 non-null    object\n",
      " 1   hour         795 non-null    int64 \n",
      " 2   platform_os  795 non-null    int64 \n",
      " 3   browser      795 non-null    object\n",
      " 4   day_of_week  795 non-null    object\n",
      " 5   brand        795 non-null    object\n",
      " 6   response     795 non-null    int64 \n",
      "dtypes: int64(3), object(4)\n",
      "memory usage: 43.6+ KB\n"
     ]
    }
   ],
   "source": [
    "path = 'data/brand_generic.csv'\n",
    "repo = \"../\"\n",
    "version = 'v1.1.2'\n",
    "\n",
    "f = dvc.api.read(path=path, \n",
    "                repo=repo, \n",
    "                rev=version)\n",
    "\n",
    "type(f)\n",
    "\n",
    "df = pd.read_csv(io.StringIO(f), sep=\",\")\n",
    "# I should fix this in the next version of the files\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['experiment', 'browser', 'day_of_week', 'brand']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['hour', 'platform_os']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cat_cols = cleaner.get_categorical_columns(df)\n",
    "num_cols = cleaner.get_numerical_columns(df)[:-1]   # Remove the target column\n",
    "\n",
    "display(cat_cols)\n",
    "display(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will move this to a script file\n",
    "# def get_col_transformer(num_cols=None, cat_cols=None):\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', max_categories=15))\n",
    "])\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('scale', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, num_cols),\n",
    "        ('cat', categorical_transformer, cat_cols)\n",
    "    ])\n",
    "    \n",
    "    # return preprocessor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pipeline = Pipeline(steps=[\n",
    "                            ('preprocessor', preprocessor),\n",
    "                            ('model', RandomForestClassifier())\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (556, 6)\n",
      "Valid shape: (179, 6)\n",
      "Test shape: (60, 6)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=['response'])\n",
    "y = df['response'].values\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size=0.25)\n",
    "print(f\"Train shape: {X_train.shape}\")\n",
    "print(f\"Valid shape: {X_valid.shape}\")\n",
    "print(f\"Test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = my_pipeline.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5251396648044693"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = clf.predict(X_valid)\n",
    "r2 = r2_score(y_valid, preds)\n",
    "acc = accuracy_score(y_valid, preds)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4748603351955307"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = mean_absolute_error(y_valid, preds)\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "27824603f874b117c43be6dbaa703ec03a436778e8f471c608241d08d6141291"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
